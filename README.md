
# Kasten K10 Scraper

Este es un script en Python para scrapear la documentaci√≥n de [Kasten K10](https://docs.kasten.io/latest/) y almacenarla en archivos Markdown.

## üìå Caracter√≠sticas

- Extrae enlaces principales e internos de la documentaci√≥n oficial.
- Descarga y limpia el contenido en formato Markdown.
- Organiza los archivos por categor√≠as.
- Ejecuta el scraping en paralelo utilizando `ThreadPoolExecutor` para mejorar la eficiencia.

## üöÄ Instalaci√≥n y uso

### 1Ô∏è‚É£ Clonar el repositorio

git clone https://github.com/tu-repo/kasten-k10-scraper.git
cd kasten-k10-scraper

### 2Ô∏è‚É£ Instalar dependencias

pip install -r requirements.txt

### 3Ô∏è‚É£ Configurar variables de entorno (opcional)

Exporta las siguientes variables de entorno seg√∫n sea necesario para personalizar la configuraci√≥n del scraper:

- `BASE_URL`: URL base de la documentaci√≥n que deseas scrapear (por defecto: `https://docs.kasten.io/latest/`).
- `DOCS_DIR`: Directorio donde se guardar√°n los documentos descargados (por defecto: `docs/`).
- `USER_AGENT`: Cadena de agente de usuario para las solicitudes HTTP (por defecto: `Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36`).
- `MAX_WORKERS`: N√∫mero de hilos para el scraping en paralelo. El valor predeterminado es el doble del n√∫mero de n√∫cleos de CPU de tu m√°quina. Ajusta este valor seg√∫n la capacidad de tu sistema y las necesidades de rendimiento.
  
Ejemplo para establecer las variables en sistemas basados en Unix/Linux:

```bash
export BASE_URL="https://docs.kasten.io/latest/"
export DOCS_DIR="docs/"
export USER_AGENT="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36"
export MAX_WORKERS=8  # Ajusta este n√∫mero seg√∫n sea necesario
```


### 4Ô∏è‚É£ Ejecutar el scraper

python scraper.py

## üìÇ Estructura del proyecto

kasten-k10-scraper/
‚îÇ‚îÄ‚îÄ docs/                # Archivos de documentaci√≥n extra√≠dos
‚îÇ‚îÄ‚îÄ scraper.py           # Script principal de scraping
‚îÇ‚îÄ‚îÄ requirements.txt     # Dependencias del proyecto
‚îÇ‚îÄ‚îÄ README.md            # Este archivo

## ‚öôÔ∏è Configuraci√≥n

- Puedes definir el n√∫mero de hilos para el scraping con la variable de entorno `MAX_WORKERS`.
- El contenido se guarda en la carpeta `docs/`.

## üìú Licencia

Este proyecto se distribuye bajo la licencia GNU General Public License v3.0.

## ü§ù Contribuir

Este proyecto es de c√≥digo abierto y las contribuciones son bienvenidas. Si deseas contribuir, por favor:

1. Forkea el repositorio.
2. Crea tu rama de caracter√≠sticas (`git checkout -b feature/AmazingFeature`).
3. Realiza tus cambios y confirma tus cambios (`git commit -m 'Add some AmazingFeature'`).
4. Sube tus cambios a la rama (`git push origin feature/AmazingFeature`).
5. Abre una Pull Request.
